{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0c1d3ab-c316-4856-8fcf-0441a68505e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Embedding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16079ab6-4788-4f76-bfc9-a243afb96a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.gutenberg.org/files/1524/1524-0.txt'  # Hamlet\n",
    "response = requests.get(url)\n",
    "text = response.text.lower()\n",
    "text = text[:200000]   # limit for faster training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b74b2439-8c61-417c-a71e-cd021e7837bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique characters: 49\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "char_to_idx = {c: i for i, c in enumerate(chars)}\n",
    "idx_to_char = {i: c for i, c in enumerate(chars)}\n",
    "vocab_size = len(chars)\n",
    "print(\"Total unique characters:\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fc886fd-be53-43ea-950f-2316286a09b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sequences: 178022\n"
     ]
    }
   ],
   "source": [
    "seq_length = 40\n",
    "X = []\n",
    "y = []\n",
    "for i in range(len(text) - seq_length):\n",
    "    seq_in = text[i:i + seq_length]\n",
    "    seq_out = text[i + seq_length]\n",
    "    X.append([char_to_idx[ch] for ch in seq_in])\n",
    "    y.append(char_to_idx[seq_out])\n",
    "\n",
    "X = np.array(X)\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "print(\"Total sequences:\", len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d21b4d1f-cfb9-482c-8729-a597de3c378a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)             │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ simple_rnn_1 (\u001b[38;5;33mSimpleRNN\u001b[0m)             │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=64, input_length=seq_length),\n",
    "    SimpleRNN(128),\n",
    "    Dense(vocab_size, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c01508aa-add7-4c15-b133-f621c5808ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m1391/1391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 39ms/step - loss: 2.3048\n",
      "Epoch 2/3\n",
      "\u001b[1m1391/1391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 44ms/step - loss: 1.9329\n",
      "Epoch 3/3\n",
      "\u001b[1m1391/1391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 43ms/step - loss: 1.8058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x23523e3dd90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, batch_size=128, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61e31687-4828-486c-83f7-3f2026043b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_with_temperature(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    log_preds = np.log(preds + 1e-12) / temperature\n",
    "    exp_preds = np.exp(log_preds)\n",
    "    probs = exp_preds / np.sum(exp_preds)\n",
    "    return np.random.choice(range(len(probs)), p=probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0459ffbc-440e-4335-8a0e-2a48de4ec94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, seed_text, length=200, temperature=1.0):\n",
    "    if len(seed_text) < seq_length:\n",
    "        seed_text = ' ' * (seq_length - len(seed_text)) + seed_text\n",
    "    seed = seed_text[-seq_length:]\n",
    "    generated = seed\n",
    "    for _ in range(length):\n",
    "        x_pred = np.array([[char_to_idx.get(c, 0) for c in seed]])\n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample_with_temperature(preds, temperature)\n",
    "        next_char = idx_to_char[next_index]\n",
    "        generated += next_char\n",
    "        seed = seed[1:] + next_char\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1766d31-a51a-4514-9a4a-7d9b7c0d69e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: '*** start of the project gutenberg ebook'\n",
      "\n",
      "Generated:\n",
      " *** start of the project gutenberg ebooke.\n",
      "\n",
      "way, but the gords indasting stald sone.\n",
      "\n",
      "hamlet.\n",
      "gurestars.\n",
      "i do the cat is but trou to this wall be shat would majuse;\n",
      "of end gupbly a vall a f on ow the ’tave to the well\n",
      "that this stoit in chation so bot the onco.\n",
      "\n",
      "porngiffald.\n",
      "\n",
      "hamlet.\n",
      "i wat their dage. so the of with you, my soter of acaicherous of o deed the his hamlet, it his berarsi bustle\n",
      "that well the the the lood that a wall barn. dreave us this munker prown him.\n",
      "\n",
      "wing.\n",
      "o deed\n",
      "his brearifu\n",
      "his some will lood,\n",
      "lay then my that the\n"
     ]
    }
   ],
   "source": [
    "seed = text[:40]\n",
    "print(\"Seed:\", repr(seed))\n",
    "print(\"\\nGenerated:\\n\", generate_text(model, seed, length=500, temperature=0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e3e12a-4deb-419d-b12f-93a3435c79da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
